# Memory Access

#### 2005 QEMU, a Fast and Portable Dynamic Translator

1. QEMU在运行时进行翻译，并将翻译出的二进制代码存到code cache中，所以翻译出的代码可以被重用，与解释器相比的优势是guest指令仅仅需要被取和解码一次。
2. 将target CPU的指令分解为一些简单的微操作。微操作的数量比target指令的数目小很多。



问题：

1. QEMU constant parameters？是干什么用的，



文章中绿色为可能在latx-sys中添加的创新点，红色为存在疑问的地方。



#### 2015 Optimizing Memory Translation Emulation in Full System Emulators

类似于STLB优化技术的综述。

页表由模拟的x86 CR3寄存器指向。

*当STLB不包含地址空间标识符（asid）时，在客户操作系统中切换进程时必须刷新STLB。*

本文对一些可能的STLB优化进行了尝试和总结，包括硬件TLB的适配优化和STLB灵活性带来的特有的优化。包括：

硬件相关优化：

受害者（victim）STLB使用一个小的、完全关联的STLB来捕获直接映射的主STLB的一些冲突缺失。

set-associative（组相联） STLB改变了主STLB，使它在每个set中包含多个表项，以减少冲突丢失。本文考虑了集合关联STLB的几种变体，包括使用最新Intel处理器的SIMD指令扩展来加速搜索的一种变体。

软件优化：

bump-the-STLB分配技术：使用一个由多个STLB组成的池和一个单独的线程将STLB冲洗
从关键路径中取出。（latx中的平行flush？）

翻译合并（Translation coalescing， XC）：XC对于堆栈访问特别有效，push和pop序列。

超级页STLB缓存超级页的翻译，否则超级页在QEMU中被视为相邻的规则大小页面的集合。基于分析的超级页查找通过动态分析和将每个模拟内存指令与针对最可能使用的页面大小进行优化的STLB查找序列相关联，进一步改进了超级页处理。这避免了需要频繁地进行多个探测（每个探测具有不同的页面大小）才能找到相应的翻译。



#### 2015 HSPT: Practical Implementation and Efficient Management of Embedded Shadow Page Tables for Cross-ISA System Virtual Machines

Our approach adopts a shared memory mapping scheme to maintain the shadow page table (SPT) using only “mmap” system call. Furthermore, this work studies the support of SPT for multi-processing in greater details.

We have come up with a different implementation to manage SPTs without using LKMs.We divided the operations on SPT into three types: 

1. Creating SPT
2. Synchronizing with guest page table (GPT) 
3. Switching SPT for different processes.

HSPT uses three methods to accomplish these operations with no LKMs: 

1. It uses a portion of the host page table as SPT to accomplish the operation of creating SPT. 
2. It uses the shared memory mapping scheme where multiple virtual pages can be mapped to the same physical page to synchronize the SPT with GPT. 
3. It uses Shared SPT to handle multi-processing in guest OSes.

The main contributions of this paper are as follows:

1. Proposed and evaluated three SPT organizations, including Shared, Private and Group Shared SPT to handle multi-processing in guest OSes. A guideline on how to select each variation is provided.

We set aside a fixed virtual space called “Guest-Dedicated Virtual Address Space” (GDVAS) from the host virtual space (as indicated in the figure). When we set aside GDVAS, each page in the guest virtual space is mapped to a page in the GDVAS.



#### BTMMU: An Efficient and Versatile Cross-ISA Memory Virtualization





## 软件页表缓存

#### 2010 Translation Caching: Skip, Don’t Walk (the Page Table)

本文讨论了几种TLB miss之后的页表缓存结构效果。

基数树页面表？本文表明，由于虚拟地址使用中的局部性，与基于哈希的表相比，基数表导致的总内存访问最多减少20%，DRAM访问最多减少400%。

对于名义大小的应用程序，TLB缺失对整体系统性能的影响在5-14%之间，即使在非虚拟化环境中也是如此。随着应用程序内存占用的增加，TLB缺失对性能的影响显著增大，在某些情况下接近50%。

缓存加速了在翻译TLB中出现miss后发生的页表遍历。本文表明，最有效的MMU缓存是Translation Cache，它存储部分地址翻译并允许页遍历硬件跳过页表的一个或多个级别。

缓存页遍历 CACHING PAGEWALKS：

1. 页表缓存 Page table caches：每个缓存表项对应单独一级的虚拟地址和物理地址的转换。每一级都分别存储。

2. 翻译缓存 Translation caches：通过完整的单级或多级虚拟地址作为索引，不需要从一个条目中获取数据来查找页表下一个较低级别的条目。所有的查找都可以彼此独立地执行。最后，MMU将选择与虚拟地址的最长前缀匹配的条目，因为它允许页面遍历跳过大多数级别。
3. 平移路径缓存：将以上两种方法结合。

文中给出了以上三种缓存的SPEC2006 fp测试数据，对统一和分割都进行了性能的比较，还有一些替代基数树页表的方案也进行了讨论。结论是认为统一翻译缓存效果最好。







# Code Cache

#### 2002 Code Cache Management Schemes for Dynamic Optimizers

可以优化例如Java这种运行时使用二进制码的语言。

本文评估了几种替代缓存管理方案，这些方案仅识别和删除足够的trace（而不是全部），以便为新trace腾出空间。现存的大部分缓存都是直接将整个cache进行刷新。

？本文使用循环缓冲区？我们可以将代码缓存未命中率降低一半。 此外，这种方法增加的额外开销非常小，并且避免了与代码缓存碎片相关的问题。

要找好缓存管理策略复杂性与其优化收益之间的平衡，防止过于复杂导致性能优化适得其反。

适用于动态翻译器和基于硬件的代码缓存机制 



#### 系统级二进制翻译器中软件代码缓存研究    师兄论文

1. 本文分析了系统级二进制翻译器中已有的指令语义模拟方案给软件代码缓存管理带来的问题，并将其总结为冲突问题和冗余问题;
2. 针对冲突问题，本文提出了多状态代码缓存方案，避免了不同状态的翻译代码块之间的冲突，降低了不必要的刷新，减少了动态翻译开销;
3. 针对冗余问题，本文提出了弱状态标签方案，消除了部分状态导致的冗余代码块，降低了翻译开销和内存占用，仅带来了非常有限的性能损失;



# 硬件辅助加速

#### Captive

The key idea is to eliminate performance bottlenecks by exploiting the existing virtualization hardware extensions originally devised for same-architecture virtualization.

论文内容：

1. We show how virtual-to-physical address translation can be accelerated through the use of virtualization extensions by mapping behavior of the guest MMU onto corresponding behavior of the host MMU.（hamt？）
2. We present a DBT system for the translation from the guest to host ISA, where a fast, block-based just-in-time (JIT) compiler that lives inside the native virtual machine compiles guest basic blocks to host native code.（使用到了kvm？）
3. We develop an efficient mechanism to emulate the guest’s memory mapped I/O devices by exploiting the MMU to detect device accesses.（设备直通？）
4. Finally, we devise an interrupt handling scheme, which correctly honors the guest’s instruction boundaries, even if one guest instruction is mapped onto several host instructions, thus implementing precise, yet efficient, guest interrupts.（guest中断？）



#  热路径优化

#### IA-32

首先翻译一次cold code, 设置一个运行时的计数器，在计数器达到阈值之后，将热点代码重新进行hot code的大量优化的翻译。



# Peephole Optimization

#### Performance Improvements via Peephole Optimization in Dynamic Binary Translation

1. 使用instptn进行优化: pxor, mulsd+addsd（主要是由于helper的上下文切换次数减少导致的性能优化？）
2. 使用live variable analysis进行活性分析，对于连续的内存访问的情况进行分析，减少LAL, LAS, SAS, SAL (L=Load, A=After, S=Store)的冗余内存访问情况。