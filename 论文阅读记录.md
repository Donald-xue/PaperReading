# 预取

## 硬件预取

#### 2024 Tyche: An Efficient and General Prefetcher for Indirect Memory Accesses

间接内存访问（ima，即A[f(B[i])]）由生产者-消费者对组成，其中消费者的内存地址来自生产者的内存数据。由于内置的值依赖特征，ima表现出较差的局部性，使得预取无效。

Tyche由三个主要组件组成：传播表（PT）、依赖链表（DCT）和地址生成队列（AGQ）。具体来说，PT负责前向传播源自跨步负载的指令依赖，以收集所有潜在的指令依赖链，而不管它们最终是否被消耗。在向前传播期间，如果遇到加载指令，DCT将触发向后传播，将链中的指令标记为有用，从而精确地提取IMA指令依赖链。最后，AGQ被设计成连续遍历依赖链并生成预取请求。

从一个跨步的访存指令作为开头前向传播，到一个非跨步的访存指令为止，从非跨步的访存指令进行后向传播，筛选出两条访存指令之间真正相关的指令依赖链。用一个单独的simple ALU对这个依赖链中的指令进行运算，再将算出来的地址交给AGQ发出预取请求。



## 软件预取

#### 1992 Design and Evaluation of a Compiler Algorithm for Prefetching

本文提出了一种将预取指令插入到密集矩阵代码中的编译算法。我们的算法识别那些可能是缓存丢失的引用，并且只对它们发出预取。

开发了一个编译器算法，使用局部性分析来选择性地只预取那些可能导致缓存丢失的引用。

在循环结构中适当位置插入预取指令，确保数据在访问时已被加载到缓存中。与软件流水线技术相结合，以隐藏预取引入的延迟。

分析了一些编译预取相关的细节，局部性分析、循环分解、预取安排等问题。

说实话没太读懂。



#### 2002 Efficient Discovery of Regular Stride Patterns in Irregular Programs and Its Use in Compiler Prefetching

该方法将跨幅信息分析和传统的边缘频率分析集成到一次分析中。

可以对SPECINT2000 中的181, 197, 254 子项的**链表**循环访问模式优化。

似乎在编译之前需要先分析出一个profile?

运行时，stride profile需要收集两种类型的信息：步幅值profile和步幅差profile。步幅差profile用于区分stride是phased（阶段性不变） stride还是alternated（交替） stride。

2. OVERVIEW OF PREFETCHING ALGORITHM

除了stride profile以外，还需要首先使用frequency profile来过滤掉显然不会从跨步预取中受益的负载（执行次数frequency少的）。

分析了三种stride profile feedback的可以预取的情况：Strong single stride (SSST) load，Phased multi-stride (PMST) load和Weak single stride (WSST) load。并对三种情况分别的识别和处理进行了比较详细的介绍。

171对应的应该是PMST？毕竟是几个数组之间来回进行访问。但同一个ld的话，似乎stride又是相同的？



# Memory Access

#### 2005 QEMU, a Fast and Portable Dynamic Translator

1. QEMU在运行时进行翻译，并将翻译出的二进制代码存到code cache中，所以翻译出的代码可以被重用，与解释器相比的优势是guest指令仅仅需要被取和解码一次。
2. 将target CPU的指令分解为一些简单的微操作。微操作的数量比target指令的数目小很多。



问题：

1. QEMU constant parameters？是干什么用的，



文章中绿色为可能在latx-sys中添加的创新点，红色为存在疑问的地方。



#### 2015 Optimizing Memory Translation Emulation in Full System Emulators

类似于STLB优化技术的综述。

页表由模拟的x86 CR3寄存器指向。

*当STLB不包含地址空间标识符（asid）时，在客户操作系统中切换进程时必须刷新STLB。*

本文对一些可能的STLB优化进行了尝试和总结，包括硬件TLB的适配优化和STLB灵活性带来的特有的优化。包括：

硬件相关优化：

受害者（victim）STLB使用一个小的、完全关联的STLB来捕获直接映射的主STLB的一些冲突缺失。

set-associative（组相联） STLB改变了主STLB，使它在每个set中包含多个表项，以减少冲突丢失。本文考虑了集合关联STLB的几种变体，包括使用最新Intel处理器的SIMD指令扩展来加速搜索的一种变体。

软件优化：

bump-the-STLB分配技术：使用一个由多个STLB组成的池和一个单独的线程将STLB冲洗
从关键路径中取出。（latx中的平行flush？）

翻译合并（Translation coalescing， XC）：XC对于堆栈访问特别有效，push和pop序列。

超级页STLB缓存超级页的翻译，否则超级页在QEMU中被视为相邻的规则大小页面的集合。基于分析的超级页查找通过动态分析和将每个模拟内存指令与针对最可能使用的页面大小进行优化的STLB查找序列相关联，进一步改进了超级页处理。这避免了需要频繁地进行多个探测（每个探测具有不同的页面大小）才能找到相应的翻译。



#### 2015 HSPT: Practical Implementation and Efficient Management of Embedded Shadow Page Tables for Cross-ISA System Virtual Machines

Our approach adopts a shared memory mapping scheme to maintain the shadow page table (SPT) using only “mmap” system call. Furthermore, this work studies the support of SPT for multi-processing in greater details.

We have come up with a different implementation to manage SPTs without using LKMs.We divided the operations on SPT into three types: 

1. Creating SPT
2. Synchronizing with guest page table (GPT) 
3. Switching SPT for different processes.

HSPT uses three methods to accomplish these operations with no LKMs: 

1. It uses a portion of the host page table as SPT to accomplish the operation of creating SPT. 
2. It uses the shared memory mapping scheme where multiple virtual pages can be mapped to the same physical page to synchronize the SPT with GPT. 
3. It uses Shared SPT to handle multi-processing in guest OSes.

The main contributions of this paper are as follows:

1. Proposed and evaluated three SPT organizations, including Shared, Private and Group Shared SPT to handle multi-processing in guest OSes. A guideline on how to select each variation is provided.

We set aside a fixed virtual space called “Guest-Dedicated Virtual Address Space” (GDVAS) from the host virtual space (as indicated in the figure). When we set aside GDVAS, each page in the guest virtual space is mapped to a page in the GDVAS.



#### BTMMU: An Efficient and Versatile Cross-ISA Memory Virtualization





## 软件页表缓存

#### 2010 Translation Caching: Skip, Don’t Walk (the Page Table)

本文讨论了几种TLB miss之后的页表缓存结构效果。

基数树页面表？本文表明，由于虚拟地址使用中的局部性，与基于哈希的表相比，基数表导致的总内存访问最多减少20%，DRAM访问最多减少400%。

对于名义大小的应用程序，TLB缺失对整体系统性能的影响在5-14%之间，即使在非虚拟化环境中也是如此。随着应用程序内存占用的增加，TLB缺失对性能的影响显著增大，在某些情况下接近50%。

缓存加速了在翻译TLB中出现miss后发生的页表遍历。本文表明，最有效的MMU缓存是Translation Cache，它存储部分地址翻译并允许页遍历硬件跳过页表的一个或多个级别。

缓存页遍历 CACHING PAGEWALKS：

1. 页表缓存 Page table caches：每个缓存表项对应单独一级的虚拟地址和物理地址的转换。每一级都分别存储。

2. 翻译缓存 Translation caches：通过完整的单级或多级虚拟地址作为索引，不需要从一个条目中获取数据来查找页表下一个较低级别的条目。所有的查找都可以彼此独立地执行。最后，MMU将选择与虚拟地址的最长前缀匹配的条目，因为它允许页面遍历跳过大多数级别。
3. 平移路径缓存：将以上两种方法结合。

文中给出了以上三种缓存的SPEC2006 fp测试数据，对统一和分割都进行了性能的比较，还有一些替代基数树页表的方案也进行了讨论。结论是认为统一翻译缓存效果最好。



## 内存映射

#### 2024 On-Demand Triggered Memory Management Unit in Dynamic Binary Translator

主要讨论了guest和host系统不同大小页面的情况下的安全问题。

用户态DBT中由于没有软件MMU，线性映射页面时如果host和guest页面大小不同会产生正确性和安全问题。用户级dbt利用线性映射，高性能，但有潜在的风险。系统级dbt采用软件MMU，消除了风险，但性能较差。我们提出了一种结合他们各自优势的新的内存管理方法，称为按需触发式内存管理单元（ODT-MMU），它将线性映射方法与风险出现时触发软件内存管理单元相结合。

我们以两种方式实现ODT-MMU: ODT-InterpMMU，一种解释风险页面访问的平台无关实现；ODT-ManipTLB，利用可编程TLB来增强风险页面访问性能。

将有风险的页面放到一个影子页表里面，访问时触发OS信号，用软件MMU单独处理。



# Code Cache

#### 2002 Code Cache Management Schemes for Dynamic Optimizers

可以优化例如Java这种运行时使用二进制码的语言。

本文评估了几种替代缓存管理方案，这些方案仅识别和删除足够的trace（而不是全部），以便为新trace腾出空间。现存的大部分缓存都是直接将整个cache进行刷新。

？本文使用循环缓冲区？我们可以将代码缓存未命中率降低一半。 此外，这种方法增加的额外开销非常小，并且避免了与代码缓存碎片相关的问题。

要找好缓存管理策略复杂性与其优化收益之间的平衡，防止过于复杂导致性能优化适得其反。

适用于动态翻译器和基于硬件的代码缓存机制 



#### 系统级二进制翻译器中软件代码缓存研究    师兄论文

1. 本文分析了系统级二进制翻译器中已有的指令语义模拟方案给软件代码缓存管理带来的问题，并将其总结为冲突问题和冗余问题;
2. 针对冲突问题，本文提出了多状态代码缓存方案，避免了不同状态的翻译代码块之间的冲突，降低了不必要的刷新，减少了动态翻译开销;
3. 针对冗余问题，本文提出了弱状态标签方案，消除了部分状态导致的冗余代码块，降低了翻译开销和内存占用，仅带来了非常有限的性能损失;



# 硬件辅助加速

#### Captive

The key idea is to eliminate performance bottlenecks by exploiting the existing virtualization hardware extensions originally devised for same-architecture virtualization.

论文内容：

1. We show how virtual-to-physical address translation can be accelerated through the use of virtualization extensions by mapping behavior of the guest MMU onto corresponding behavior of the host MMU.（hamt？）
2. We present a DBT system for the translation from the guest to host ISA, where a fast, block-based just-in-time (JIT) compiler that lives inside the native virtual machine compiles guest basic blocks to host native code.（使用到了kvm？）
3. We develop an efficient mechanism to emulate the guest’s memory mapped I/O devices by exploiting the MMU to detect device accesses.（设备直通？）
4. Finally, we devise an interrupt handling scheme, which correctly honors the guest’s instruction boundaries, even if one guest instruction is mapped onto several host instructions, thus implementing precise, yet efficient, guest interrupts.（guest中断？）



#  热路径优化

#### IA-32

首先翻译一次cold code, 设置一个运行时的计数器，在计数器达到阈值之后，将热点代码重新进行hot code的大量优化的翻译。



# Peephole Optimization

#### Performance Improvements via Peephole Optimization in Dynamic Binary Translation

1. 使用instptn进行优化: pxor, mulsd+addsd（主要是由于helper的上下文切换次数减少导致的性能优化？）
2. 使用live variable analysis进行活性分析，对于连续的内存访问的情况进行分析，减少LAL, LAS, SAS, SAL (L=Load, A=After, S=Store)的冗余内存访问情况。