# Memory Access

#### 2005 QEMU, a Fast and Portable Dynamic Translator

1. QEMU在运行时进行翻译，并将翻译出的二进制代码存到code cache中，所以翻译出的代码可以被重用，与解释器相比的优势是guest指令仅仅需要被取和解码一次。
2. 将target CPU的指令分解为一些简单的微操作。微操作的数量比target指令的数目小很多。



问题：

1. QEMU constant parameters？是干什么用的，



文章中绿色为可能在latx-sys中添加的创新点，红色为存在疑问的地方。



#### 2015 Optimizing Memory Translation Emulation in Full System Emulators

Many STLB optimizations implement and analysis: 

1. measures where time goes during memory emulation

2. applicability of hardware-inspired TLB optimizations to software emulated TLB

3. leverages the flexibility of a software TLB to propose innovative and effective memory emulation performance improvement techniques, such as: 

   dynamically sized STLB, profiling-based superpage lookup, and translation coalescing.

4. demonstrates that they improve overall performance by an average of 24.4% and as much as 48.0% for a memory-intensive workload.



#### 2015 HSPT: Practical Implementation and Efficient Management of Embedded Shadow Page Tables for Cross-ISA System Virtual Machines

Our approach adopts a shared memory mapping scheme to maintain the shadow page table (SPT) using only “mmap” system call. Furthermore, this work studies the support of SPT for multi-processing in greater details.

We have come up with a different implementation to manage SPTs without using LKMs.We divided the operations on SPT into three types: 

1. Creating SPT
2. Synchronizing with guest page table (GPT) 
3. Switching SPT for different processes.

HSPT uses three methods to accomplish these operations with no LKMs: 

1. It uses a portion of the host page table as SPT to accomplish the operation of creating SPT. 
2. It uses the shared memory mapping scheme where multiple virtual pages can be mapped to the same physical page to synchronize the SPT with GPT. 
3. It uses Shared SPT to handle multi-processing in guest OSes.

The main contributions of this paper are as follows:

1. Proposed and evaluated three SPT organizations, including Shared, Private and Group Shared SPT to handle multi-processing in guest OSes. A guideline on how to select each variation is provided.

We set aside a fixed virtual space called “Guest-Dedicated Virtual Address Space” (GDVAS) from the host virtual space (as indicated in the figure). When we set aside GDVAS, each page in the guest virtual space is mapped to a page in the GDVAS.



#### BTMMU: An Efficient and Versatile Cross-ISA Memory Virtualization







# Code Cache

#### 2002 Code Cache Management Schemes for Dynamic Optimizers

可以优化例如Java这种运行时使用二进制码的语言。

本文评估了几种替代缓存管理方案，这些方案仅识别和删除足够的trace（而不是全部），以便为新trace腾出空间。现存的大部分缓存都是直接将整个cache进行刷新。

？本文使用循环缓冲区？我们可以将代码缓存未命中率降低一半。 此外，这种方法增加的额外开销非常小，并且避免了与代码缓存碎片相关的问题。

要找好缓存管理策略复杂性与其优化收益之间的平衡，防止过于复杂导致性能优化适得其反。

适用于动态翻译器和基于硬件的代码缓存机制 



#### 系统级二进制翻译器中软件代码缓存研究    师兄论文

1. 本文分析了系统级二进制翻译器中已有的指令语义模拟方案给软件代码缓存管理带来的问题，并将其总结为冲突问题和冗余问题;
2. 针对冲突问题，本文提出了多状态代码缓存方案，避免了不同状态的翻译代码块之间的冲突，降低了不必要的刷新，减少了动态翻译开销;
3. 针对冗余问题，本文提出了弱状态标签方案，消除了部分状态导致的冗余代码块，降低了翻译开销和内存占用，仅带来了非常有限的性能损失;



# 硬件辅助加速

#### Captive

The key idea is to eliminate performance bottlenecks by exploiting the existing virtualization hardware extensions originally devised for same-architecture virtualization.

论文内容：

1. We show how virtual-to-physical address translation can be accelerated through the use of virtualization extensions by mapping behavior of the guest MMU onto corresponding behavior of the host MMU.（hamt？）
2. We present a DBT system for the translation from the guest to host ISA, where a fast, block-based just-in-time (JIT) compiler that lives inside the native virtual machine compiles guest basic blocks to host native code.（使用到了kvm？）
3. We develop an efficient mechanism to emulate the guest’s memory mapped I/O devices by exploiting the MMU to detect device accesses.（设备直通？）
4. Finally, we devise an interrupt handling scheme, which correctly honors the guest’s instruction boundaries, even if one guest instruction is mapped onto several host instructions, thus implementing precise, yet efficient, guest interrupts.（guest中断？）



#  热路径优化

#### IA-32

首先翻译一次cold code, 设置一个运行时的计数器，在计数器达到阈值之后，将热点代码重新进行hot code的大量优化的翻译。



# Peephole Optimization

#### Performance Improvements via Peephole Optimization in Dynamic Binary Translation

1. 使用instptn进行优化: pxor, mulsd+addsd（主要是由于helper的上下文切换次数减少导致的性能优化？）
2. 使用live variable analysis进行活性分析，对于连续的内存访问的情况进行分析，减少LAL, LAS, SAS, SAL (L=Load, A=After, S=Store)的冗余内存访问情况。