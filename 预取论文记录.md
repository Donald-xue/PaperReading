# 数据预取论文记录

## 综述

### 1996 A Survey of Data Prefetching Techniques

**软件预取**

优点：有编译时信息，可以更准确的发送prefetch指令。

缺点：需要插入prefatch指令，增加了cpu的工作量。静态生成的，无法在执行过程中应对一些动态的意外情况（如：预取块被提前取出，需要re-prefetch。）。另外，其预取的地址需要额外计算或寄存器来进行存储，如果寄存器不够用还要去内存里先取得地址。

文中：loop-based prefetching，一个简单的stream预取例子，--> software piplining可以解决。该方式对简单的循环内数组使用循环变量作为索引的科学计算程序效果好，对一般程序或涉及到图或指针链表的程序效果有限。许多通用应用程序相对较高的时间局域性常常导致较高的缓存利用率，从而降低了预取的好处。



**硬件预取**

优点：由特殊的硬件单元来监视访存行为并推断预取机会，并发起预取。不需要显式的插入prefetch指令，没有指令overhead。

缺点：由于没有编译时信息，会导致预取不准确。错误的预测预取会导致cache pollution和对主存带宽的浪费。



1. 顺序预取 Sequential prefetching

cache块本身就是一种顺序预取，但如果cache块太大，则会引起cache pollution，false sharing，替换粒度太大等问题。

OBL（one block lookahead）预取方式是简单的顺序预取。在OBL预取方式中，tagged prefetch比prefetch on miss的效果更好。如果one block不能掩盖访存迟延，one可以增加为k。



2. 以任意的步长预取 Prefetching with arbitrary strides

(1) Lee, et al. [16]，looking ahead in the instruction stream to prefetch，提前将指令流前的访存指令计算出地址并预取。可以做到任意data access patterns的预取，但瓶颈在于lookahead buffer的大小和遇到跳转的预测准确率。

*dbt可以在翻译的时候发出这一类预取？*

(2) *Stride Prefetch*： Chen and Baer [4]对同一个ld/st的上下两次访存地址的差值做比较，用这个∆来直接预测下一次同一ld/st的访存地址，如果预测地址与实际观测地址不符合，则停止预取，非常激进。

一个单独的缓存称为引用预测表（RPT，reference prediction table），它只保存most recently used的内存指令的信息。优化了一个除pc之外的lookahead pc，专门用来进行提前的预取。

发现软件初始化预取对于使用**间接引用**来计算预取地址的某些不规则访问模式比RPT更有效。

Harrison and Mehrotra [12]优化了RPT预取的功能，允许通过指针连接的数据对象的预取。



**二进制翻译器预取**

优点：？ 节省硬件硅面积

缺点：似乎结合了以上两种预取的缺点，既没有编译时信息，无法准确预测；又要插入预取指令增加工作量。

dbt预取更像硬件预取，因为没有编译信息可以借助。



### 2016 A Survey of Recent Prefetching Techniques for Processor Caches

**硬件预取**

1. “Next-K” line prefetcher



2. Stride & Stream Prefetcher

Jouppi [1990] 使用单独的 stream buffer 来存放prefetch data，sequential cache blocks，防止了cache pollution。L1 cache miss后从这个buffer里面取用数据。

Joseph andGrunwald [1997] 采用马尔可夫转移图的方式，对当前miss address的下一可能address进行记录并记录其不同后继address的可能性，以此来预测后继address。

Sherwood et al. [2000] 也是使用单独的 stream buffer 来存放prefetch data，但其预取的address不是固定的stride，如sequential，而是由一个地址预测器给出的推测地址。在Jouppi上进行了改进。他们使用了步进过滤的马尔可夫预测器，只有连续观察到2次相同stride的情况下才更新预测器中的stride。

Sair et al. [2002] 通过分析miss load streams来将其分类，分为stride, next-line, same-object, and pointer-based miss stream四类。分别对四种pattern进行了处理，提出了“Pointer variability”和“Object fan out”来分析和缓解最具挑战性的pointer-based miss stream。

Iacobovici et al. [2004] 提出了multi-stride prefetcher。可以预取包含多个不同stride的stream。如+2, +2, +1, +2, +2, +1......

Zhu et al. [2010] 在存储访问的地址信息以外还存储了访问间隔时间信息，用于减轻了缓存污染和内存BW浪费。

Kim et al. [2014] 跟踪多个访问流，用于分析所有可能的stride streams。可以跳过一些stream，进行其他stream的prefetch。

Wenisch et al. [2005] 提出了在共享内存多处理器中的时间相关memory stream，每个sharer之间访存地址都有相同的顺序并一起发生。对数组和LDS都有效果。

Somogyi et al. [2006] 检测代码相关的空间访问模式，比基于地址的预测器实现了更高的预测覆盖率。

Somogyi et al. [2009] 提出了一种时间+空间memory stream协同工作的预测方式。



3. Correlation prefetching 相关性预取

*Correlation（相关性）* 指的是如果某个内存地址 A 被访问过之后，常常会紧接着访问另一个地址 B，那么我们说 A 和 B 之间存在访问相关性。Correlation Prefetching 就是通过记录这些相关模式，在访问 A 时，就可以提前预取 B 到缓存。

*地址CoR（Address CoR）*在内存访问和缓存预取中指的是通过分析内存访问的连续性或规律性，预测未来的内存访问地址。

Lai et al. [2001] 通过分析cache中的死块（直到换出之前都不会再用到的），加上地址CoR"（Address CoR）  "Address Continuity of Reference"（地址引用的连续性）分析，预测将访问的块，将其存放到cache中的死块位置。但CoR分析的内存开销很大。

Nesbit and Smith [2004] 提出了global history buffer (GHB) 结构来代替传统的固定大小的表格来进行miss address的存储。用prefetch key进行索引，并用一个地址链表来进行数据存储。同一个链表中的address都有同样的key，可以根据多个链表中的数据来分析不同的stride，采用different history-based prefetching techniques。

Chou [2007] 将程序执行分为epochs，将传统对于单个miss数据的预取改变为对于一个epoch的预取，减少了地址CoR的数据量，利用内存级并行来隐藏对于在内存中的table访问的延迟。（实际上就是一次预取更大的数据量？一次预取一个epoch内的所有所需数据）。

Liu et al. [2012] 利用miss CoR-based ，将时间和空间相近的两次miss进行分析，将CoR分析后的元数据压缩，与data block存放到一起，可以存放很大数据量的元数据，并可以用最小的开销将其从内存加载。

Roth et al. [1998] 提出了一种基于依赖的预取，该技术通过识别计算LDS（Link Data Structure）元素地址的程序内核来工作。当一个地址被加载时，将预测消耗该地址的loads，并立即发出这些loads的预取，通过这种方式，利用依赖信息。仅对LDS遍历的loads进行预取，保证了时效性。（怎么识别LDS？）

Panda and Balachandran [2014] 提出在多核并行程序中一个核发生的miss stream通常会在一段时间后发生在另一个核中。提出了cross-core spatial streaming prefetch technique。

Manikantan et al. [2011] 提出预取器使用两层miss数据来进行训练，它们将primary miss表示为向下一级缓存/内存发起请求，而将secondary miss表示为primary miss请求的数据尚未到达缓存的请求。比以往的只使用primary miss训练的prefetcher更准确。

Jain and Lin [2013] 提出了irregular stream buffer，分析了不规则访存流的时间相关性，并将一组相关的物理地址转换到一个新地址空间中，使他们变为连续的地址。将irregular的地址流变成顺序预取地址流。而且他们的预取元数据可以存在片上，是同时时间和空间连续的，可以分析LLC的access流，而不仅仅是miss流，更加准确。

Hu et al. [2003] 使用tag-based Correlation prefetching，缩小了CoR元数据的所需存储大小。

Sharma et al. [2005] 提出tag concentration zones (TCzones)。该prefetcher可以通过tag pattern或stride两种模式进行prefetch。

**Helper-Thread-Based Prefetching**

当主线程执行程序时，另一个线程可以冗余地执行程序的完整版本或简化版本，以推测地生成用于执行预取的数据地址。

Annavaram et al. [2001b] 采用precomputation-based的方法，当指令被fetch到I-cache时，就计算ld/st指令的地址依赖关系。根据依赖图提前计算并发出prefetch请求。

Luk [2001] 提出软件控制的预执行方法，可以比较准确的预测irregular access patterns。通过helper thread执行完整的程序而非精简的程序。

Collins et al. [2001b] 将空闲的硬件部分利用为推测线程，推测线程也可以发起一个推测线程。他们的推测线程只prefetch static loads, called delinquent loads，这样可以减少对处理器资源的争用，*delinquent loads*可以导致80%的cache miss。

Collins et al. [2002] 使用 pointer cache (PtC) 来提高在precomputation 线程中对 pointer-traversing codes 的预取效果。

Aamodt et al. [2002]提出target point和trigger point的概念，但实际上还是发起多个helper threads来提前推测执行并预取。

**Ganusov and Burtscher [2006] **感觉这一篇跟翻译器所需的方式比较相似。单独开启一个helper thread，阻塞等待主线程的miss情况，监控主线程的RoB提交情况。如果预取的数据被访问，相应的ld指令被标记为该数据的consumer。当以后这个ld被commit的时候，就向helper thread发起prefetch。



4. Spatial prefetchers



5. Temporal prefetchers



## 硬件预取



## 软件预取



## 二进制翻译器+预取

